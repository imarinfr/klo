% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mikl.r
\name{entg}
\alias{entg}
\alias{mig}
\alias{entkl}
\alias{mikl}
\title{Estimates of the differential entropy and mutual information}
\usage{
entg(x)

mig(x, y)

entkl(x, type = "klo", k = 1)

mikl(x, y, type = "klo", k = 1)
}
\arguments{
\item{x, y}{n-by-d numeric matrices, in which the n rows correspond to observations
and the d columns to variables (or coordinates) of the multivariate
distributions}

\item{type}{is the type of estimator, \code{'kl'} for the Kozachenko-Leonenko and
\code{'klo'} (default) for its offset version.}

\item{k}{is the rank of the nearest neighbor for which to search, \code{1},
the nearest neighbor (default), \code{2}, the second nearest,
and so on.}
}
\description{
TO COMPLETE
}
\section{Differential entropy estimates}{

\itemize{
  \item\code{entG}  Gaussian estimate of the differential entropy of the
                    multivariate random variables \code{x} and \code{y}.
                    If both \code{x} and \code{y} are multivariate Gaussians,
                    then the estimate is asymptotically unbiased, otherwise
                    it is just an approximation
  \item\code{entkl} The Kozachenko-Leonenko (KL) estimate of the
                    differential entropy of the multivariate random variable
                    \code{x}
}
}

\section{Mutual information entropy estimates}{

\itemize{
  \item\code{miG}   Gaussian estimate of mutual information between the
                    multivariate random variables \code{x} and \code{y}.
                    If both \code{x} and \code{y} are multivariate Gaussians,
                    then the estimate is asymptotically unbiased, otherwise
                    it is just an approximation
  \item\code{mikl}  The Kozachenko-Leonenko (KL) estimate of the
                    mutual information of the multivariate random variable
                    \code{x}
}
}

\examples{
# ADD EXAMPLES HERE
}
